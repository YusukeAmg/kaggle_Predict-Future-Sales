{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "# plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# preprocess\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# model\n",
    "import lightgbm as lgb\n",
    "\n",
    "# other\n",
    "import time\n",
    "import sys\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv('../data/input/items.csv')\n",
    "shops = pd.read_csv('../data/input/shops.csv')\n",
    "cats = pd.read_csv('../data/input/item_categories.csv')\n",
    "train = pd.read_csv('../data/input/sales_train.csv')\n",
    "# set index to ID to avoid droping it later\n",
    "test  = pd.read_csv('../data/input/test.csv').set_index('ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing outlier, negative value\n",
    "train = train[train.item_cnt_day < 100000]\n",
    "train = train[train.item_price < 1250]\n",
    "\n",
    "median = train[(train.shop_id==32)&\\\n",
    "                     (train.item_id==2973)&\\\n",
    "                     (train.date_block_num==4)&\\\n",
    "                     (train.item_price>0)].item_price.median()\n",
    "train.loc[train.item_price < 0, 'item_price'] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Якутск Орджоникидзе, 56\n",
    "train.loc[train.shop_id == 0, 'shop_id'] = 57\n",
    "test.loc[test.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "train.loc[train.shop_id == 1, 'shop_id'] = 58\n",
    "test.loc[test.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "train.loc[train.shop_id == 10, 'shop_id'] = 11\n",
    "test.loc[test.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess shops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column:shop_city_name\n",
    "shops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "shops['city_name'] = shops['shop_name'].apply(lambda x:x.split(' ')[0])\n",
    "# proofreading shop_city_name\n",
    "shops.loc[shops['city_name']=='!Якутск', \\\n",
    "         'city_name'] = 'Якутск'\n",
    "# Encoding\n",
    "shops['city_code'] = LabelEncoder().fit_transform(shops['city_name'])\n",
    "shops = shops[['shop_id','city_code']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats['split'] = cats['item_category_name'].str.split('-')\n",
    "cats['type'] = cats['split'].map(lambda x: x[0].strip())\n",
    "cats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n",
    "\n",
    "# sub type\n",
    "cats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "cats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\n",
    "cats = cats[['item_category_id','type_code', 'subtype_code']]\n",
    "\n",
    "# How deal with Чистые носители (штучные) & blank media (piece) ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.drop(['item_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Monthly Sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data is (shop_id) x (item_id)\n",
    "# so create train-matrix:(shop_id) x (item_id)\n",
    "\n",
    "matrix = []\n",
    "cols = ['date_block_num','shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = train[train.date_block_num==i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())),\\\n",
    "                           dtype='int16'))\n",
    "\n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix['item_id'] = matrix['item_id'].astype(np.int16)\n",
    "matrix.sort_values(cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_cnt_day':['sum']})\n",
    "group.columns = ['item_cnt_month']\n",
    "group.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, group, on=cols, how='left')\n",
    "matrix['item_cnt_month'] = (matrix['item_cnt_month'].fillna(0).clip(0, 20).astype(np.float16))\n",
    "\n",
    "train_month = matrix.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['date_block_num'] = 34\n",
    "test['date_block_num'] = test['date_block_num'].astype(np.int8)\n",
    "test['shop_id'] = test['shop_id'].astype(np.int8)\n",
    "test['item_id'] = test['item_id'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.concat([matrix, test], ignore_index=True, sort=False, keys=cols)\n",
    "matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shops/Items/Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, shops, on='shop_id', how='left')\n",
    "matrix = pd.merge(matrix, items, on='item_id', how='left')\n",
    "matrix = pd.merge(matrix, cats, on='item_category_id', how='left')\n",
    "matrix['city_code'] = matrix['city_code'].astype(np.int8)\n",
    "matrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\n",
    "matrix['type_code'] = matrix['type_code'].astype(np.int8)\n",
    "matrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_feature(df, lags, col):\n",
    "    tmp = df[['date_block_num', 'shop_id', 'item_id', col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num', 'shop_id', 'item_id', col+'_lag_'+str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = lag_feature(df=matrix, lags=[1, 2, 3, 4, 5, 6, 9, 12], col='item_cnt_month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean encoded features\n",
    "groupby  \n",
    " - date_block_num\n",
    " - date_block_num, item_id\n",
    " - date_block_num, shop_id\n",
    " - date_block_num, item_category_id\n",
    " - date_block_num, shop_id, item_category_id\n",
    " - date_block_num, shop_id, type_code\n",
    " - date_block_num, shop_id, subtype_code\n",
    " - date_block_num, city_code\n",
    " - date_block_num, item_id, city_code\n",
    " - date_block_num, type_code\n",
    " - date_block_num, subtype_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby('date_block_num').agg({'item_cnt_month':['mean']})\n",
    "group.columns = ['date_avg_item_cnt']\n",
    "group.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, group, on=['date_block_num'], how='left')\n",
    "matrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(df=matrix, lags=[1], col='date_avg_item_cnt')\n",
    "matrix.drop('date_avg_item_cnt', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month':['mean']})\n",
    "group.columns = ['date_item_avg_item_cnt']\n",
    "group.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id'], how='left')\n",
    "matrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)\n",
    "matrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.786548614501953"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_shop_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1,2,3,6,12], 'date_shop_avg_item_cnt')\n",
    "matrix.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "ts - time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.188655853271484"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_cat_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_category_id'], how='left')\n",
    "matrix['date_cat_avg_item_cnt'] = matrix['date_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_cat_avg_item_cnt')\n",
    "matrix.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.713069438934326"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_cat_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\n",
    "matrix['date_shop_cat_avg_item_cnt'] = matrix['date_shop_cat_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_cat_avg_item_cnt')\n",
    "matrix.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.671252727508545"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_type_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'type_code'], how='left')\n",
    "matrix['date_shop_type_avg_item_cnt'] = matrix['date_shop_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_type_avg_item_cnt')\n",
    "matrix.drop(['date_shop_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.611689329147339"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = ['date_shop_subtype_avg_item_cnt']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\n",
    "matrix['date_shop_subtype_avg_item_cnt'] = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_shop_subtype_avg_item_cnt')\n",
    "matrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.875775575637817"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'city_code'], how='left')\n",
    "matrix['date_city_avg_item_cnt'] = matrix['date_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_city_avg_item_cnt')\n",
    "matrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.54254698753357"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'item_id', 'city_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_item_city_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'city_code'], how='left')\n",
    "matrix['date_item_city_avg_item_cnt'] = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_item_city_avg_item_cnt')\n",
    "matrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9697887897491455"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'type_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_type_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'type_code'], how='left')\n",
    "matrix['date_type_avg_item_cnt'] = matrix['date_type_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_type_avg_item_cnt')\n",
    "matrix.drop(['date_type_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.113353967666626"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "group = matrix.groupby(['date_block_num', 'subtype_code']).agg({'item_cnt_month': ['mean']})\n",
    "group.columns = [ 'date_subtype_avg_item_cnt' ]\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num', 'subtype_code'], how='left')\n",
    "matrix['date_subtype_avg_item_cnt'] = matrix['date_subtype_avg_item_cnt'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'date_subtype_avg_item_cnt')\n",
    "matrix.drop(['date_subtype_avg_item_cnt'], axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Features\n",
    "Price trend for the last six months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['item_id'], how='left')\n",
    "matrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\n",
    "group.columns = ['date_item_avg_item_price']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\n",
    "matrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1, 2, 3, 4, 5, 6]\n",
    "matrix = lag_feature(df=matrix, lags=lags, col='date_item_avg_item_price')\n",
    "\n",
    "for i in lags:\n",
    "    matrix['delta_price_lag_'+str(i)] = \\\n",
    "    (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price'])\\\n",
    "    / matrix['item_avg_item_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_price_lag_'+str(i)]:\n",
    "            return row['delta_price_lag_'+str(i)]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.42483973503113"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "matrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\n",
    "matrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\n",
    "matrix['delta_price_lag'].fillna(0, inplace=True)\n",
    "\n",
    "# https://stackoverflow.com/questions/31828240/first-non-null-value-per-row-from-a-list-of-pandas-columns/31828559\n",
    "# matrix['price_trend'] = matrix[['delta_price_lag_1','delta_price_lag_2','delta_price_lag_3']].bfill(axis=1).iloc[:, 0]\n",
    "# Invalid dtype for backfill_2d [float16]\n",
    "\n",
    "fetures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n",
    "    fetures_to_drop += ['delta_price_lag_'+str(i)]\n",
    "\n",
    "matrix.drop(fetures_to_drop, axis=1, inplace=True)\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['revenue'] = train['item_price'] * train['item_cnt_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = train.groupby(['date_block_num', 'shop_id']).agg({'revenue':['sum']})\n",
    "group.columns = ['date_shop_revenue']\n",
    "group.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\n",
    "matrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\n",
    "group.columns = ['shop_avg_revenue']\n",
    "group.reset_index(inplace=True)\n",
    "\n",
    "matrix = pd.merge(matrix, group, on=['shop_id'], how='left')\n",
    "matrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n",
    "\n",
    "matrix['delta_revenue'] = \\\n",
    "(matrix['date_shop_revenue'] - matrix['shop_avg_revenue'])/ matrix['shop_avg_revenue']\n",
    "matrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], 'delta_revenue')\n",
    "\n",
    "matrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Feature\n",
    "month's days count, item-shop last&first sale, item last&first sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'], format=\"%d.%m.%Y\")\n",
    "train['year'] = train.date.dt.year\n",
    "train['month'] = train.date.dt.month\n",
    "train['day'] = train.date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create month & number of days in a month\n",
    "matrix['month'] = matrix['date_block_num'] % 12\n",
    "days = pd.Series([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "matrix['day_cnt'] = matrix['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Months since the last sale for each shop/item pair and for item only. I use programing approach.\n",
    "\n",
    "<i>\n",
    "    Create HashTable with key equals to {shop_id,item_id} and value equals to date_block_num.  \n",
    "    Iterate data from the top. Foreach row if {row.shop_id,row.item_id} is not present in the table, then add it to the table and set its value to row.  \n",
    "    date_block_num. if HashTable contains key, then calculate the difference beteween cached value and row.date_block_num.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts = time.time()\n",
    "\n",
    "cache = {}\n",
    "matrix['item_shop_last_sale'] = -1\n",
    "matrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\n",
    "\n",
    "\"\"\"\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = str(row.item_id)+' '+str(row.shop_id)\n",
    "    \n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        \n",
    "        matrix.at[idx, 'item_shop_last_sale'] = \\\n",
    "        row.date_block_num - last_date_block_num\n",
    "        \n",
    "        cache[key] = row.date_block_num\n",
    "\"\"\"\n",
    "\n",
    "for row in matrix.itertuples():\n",
    "    idx = getattr(row, 'Index')\n",
    "    item_id = getattr(row, 'item_id')\n",
    "    shop_id = getattr(row, 'shop_id')\n",
    "    date_block_num = getattr(row, 'date_block_num')\n",
    "    item_cnt_month = getattr(row, 'item_cnt_month')\n",
    "    \n",
    "    key = str(item_id) + \" \" + str(shop_id)\n",
    "    if key not in cache:\n",
    "        if item_cnt_month != 0:\n",
    "            cache[key] = date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        matrix.at[idx, 'item_shop_last_sale'] = \\\n",
    "            date_block_num - last_date_block_num\n",
    "        cache[key] = date_block_num\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts = time.time()\n",
    "\n",
    "cache = {}\n",
    "matrix['item_last_sale'] = -1\n",
    "matrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\n",
    "\n",
    "\"\"\"\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = row.item_id\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month!=0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if row.date_block_num>last_date_block_num:\n",
    "            matrix.at[idx, 'item_last_sale'] = \\\n",
    "            row.date_block_num - last_date_block_num\n",
    "            \n",
    "            cache[key] = row.date_block_num\n",
    "\"\"\"\n",
    "\n",
    "for row in matrix.itertuples():\n",
    "    idx = getattr(row, 'Index')\n",
    "    item_id = getattr(row, 'item_id')\n",
    "    item_cnt_month = getattr(row, 'item_cnt_month')\n",
    "    date_block_num = getattr(row, 'date_block_num')\n",
    "    \n",
    "    key = item_id\n",
    "    if key not in cache:\n",
    "        if item_cnt_month != 0:\n",
    "            cache[key] = date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if date_block_num > last_date_block_num:\n",
    "            matrix.at[idx, 'item_last_sale'] =\\\n",
    "            date_block_num - last_date_block_num\n",
    "            cache[key] = date_block_num\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts = time.time()\n",
    "\n",
    "matrix['item_shop_first_sale'] = \\\n",
    "matrix['date_block_num'] - \\\n",
    "matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "\n",
    "matrix['item_first_sale'] = \\\n",
    "matrix['date_block_num'] - \\\n",
    "matrix.groupby('item_id')['date_block_num'].transform('min')\n",
    "\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easier & faster method to calculate first & last sale item sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.153665542602539\n"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "# Get the list of block for each item was sold from monthly train data\n",
    "sale_group = train_month.groupby('item_id')['date_block_num'].\\\n",
    "    apply(list).reset_index(name='date_block_num')\n",
    "\n",
    "# Get the first & last element from the block list\n",
    "sale_group['item_first_sale'] = sale_group['date_block_num'].apply(lambda x:x[0])\n",
    "sale_group['item_last_sale'] = sale_group['date_block_num'].apply(lambda x:x[-1])\n",
    "\n",
    "# Fill NA with -1(there is no sales)\n",
    "sale_group = sale_group.fillna(-1)\n",
    "\n",
    "#display(sale_group)\n",
    "\n",
    "# Merge with main dataset\n",
    "\"\"\"\n",
    "matrix = pd.merge(\n",
    "    matrix,\n",
    "    sale_group.drop('data_block_num', axis=1), \n",
    "    on=['item_id'],\n",
    "    how='left'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "matrix = pd.merge(\n",
    "    matrix, sale_group.drop('date_block_num', axis=1),\n",
    "    on=['item_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(time.time() - ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.254536390304565\n"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "\n",
    "# Get the list of block for each item was sold from monthly train data\n",
    "sale_group = train_month.groupby(['item_id', 'shop_id'])['date_block_num'].\\\n",
    "    apply(list).reset_index(name='date_block_num')\n",
    "\n",
    "# Get the first & last element from the block list\n",
    "sale_group['item_shop_first_sale'] = sale_group['date_block_num'].apply(lambda x:x[0])\n",
    "sale_group['item_shop_last_sale'] = sale_group['date_block_num'].apply(lambda x:x[-1])\n",
    "\n",
    "# Fill NA with -1(there is no sales)\n",
    "sale_group = sale_group.fillna(-1)\n",
    "\n",
    "#display(sale_group)\n",
    "\n",
    "# Merge with main dataset\n",
    "matrix = pd.merge(\n",
    "    matrix,\n",
    "    sale_group.drop('date_block_num', axis=1), \n",
    "    on=['item_id', 'shop_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(time.time() - ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final preparations\n",
    "Because of the using 12 as lag value drop first 12 months. Also drop all the columns with this month calculated values (other words which can not be calcucated for the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753870964050293"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "matrix = matrix[matrix.date_block_num > 11]\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing lags brings a lot of nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8967940807342529"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = time.time()\n",
    "def fill_na(df):\n",
    "    for col in df.columns:\n",
    "        if ('_lag_' in col) & (df[col].isnull().any()):\n",
    "            if ('item_cnt' in col):\n",
    "                df[col].fillna(0, inplace=True)         \n",
    "    return df\n",
    "\n",
    "matrix = fill_na(matrix)\n",
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date_block_num', 'shop_id', 'item_id', 'item_cnt_month', 'city_code',\n",
       "       'item_category_id', 'type_code', 'subtype_code', 'item_cnt_month_lag_1',\n",
       "       'item_cnt_month_lag_2', 'item_cnt_month_lag_3', 'item_cnt_month_lag_4',\n",
       "       'item_cnt_month_lag_5', 'item_cnt_month_lag_6', 'item_cnt_month_lag_9',\n",
       "       'item_cnt_month_lag_12', 'date_avg_item_cnt_lag_1',\n",
       "       'date_shop_avg_item_cnt_lag_1', 'date_shop_avg_item_cnt_lag_2',\n",
       "       'date_shop_avg_item_cnt_lag_3', 'date_shop_avg_item_cnt_lag_6',\n",
       "       'date_shop_avg_item_cnt_lag_12', 'date_cat_avg_item_cnt_lag_1',\n",
       "       'date_shop_cat_avg_item_cnt_lag_1', 'date_shop_type_avg_item_cnt_lag_1',\n",
       "       'date_shop_subtype_avg_item_cnt_lag_1', 'date_city_avg_item_cnt_lag_1',\n",
       "       'date_item_city_avg_item_cnt_lag_1', 'date_type_avg_item_cnt_lag_1',\n",
       "       'date_subtype_avg_item_cnt_lag_1', 'delta_price_lag',\n",
       "       'delta_revenue_lag_1', 'month', 'day_cnt', 'item_first_sale',\n",
       "       'item_last_sale', 'item_shop_first_sale', 'item_shop_last_sale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5694622 entries, 4111216 to 9805837\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                Dtype  \n",
      "---  ------                                -----  \n",
      " 0   date_block_num                        int8   \n",
      " 1   shop_id                               int8   \n",
      " 2   item_id                               int16  \n",
      " 3   item_cnt_month                        float16\n",
      " 4   city_code                             int8   \n",
      " 5   item_category_id                      int8   \n",
      " 6   type_code                             int8   \n",
      " 7   subtype_code                          int8   \n",
      " 8   item_cnt_month_lag_1                  float16\n",
      " 9   item_cnt_month_lag_2                  float16\n",
      " 10  item_cnt_month_lag_3                  float16\n",
      " 11  item_cnt_month_lag_4                  float16\n",
      " 12  item_cnt_month_lag_5                  float16\n",
      " 13  item_cnt_month_lag_6                  float16\n",
      " 14  item_cnt_month_lag_9                  float16\n",
      " 15  item_cnt_month_lag_12                 float16\n",
      " 16  date_avg_item_cnt_lag_1               float16\n",
      " 17  date_shop_avg_item_cnt_lag_1          float16\n",
      " 18  date_shop_avg_item_cnt_lag_2          float16\n",
      " 19  date_shop_avg_item_cnt_lag_3          float16\n",
      " 20  date_shop_avg_item_cnt_lag_6          float16\n",
      " 21  date_shop_avg_item_cnt_lag_12         float16\n",
      " 22  date_cat_avg_item_cnt_lag_1           float16\n",
      " 23  date_shop_cat_avg_item_cnt_lag_1      float16\n",
      " 24  date_shop_type_avg_item_cnt_lag_1     float16\n",
      " 25  date_shop_subtype_avg_item_cnt_lag_1  float16\n",
      " 26  date_city_avg_item_cnt_lag_1          float16\n",
      " 27  date_item_city_avg_item_cnt_lag_1     float16\n",
      " 28  date_type_avg_item_cnt_lag_1          float16\n",
      " 29  date_subtype_avg_item_cnt_lag_1       float16\n",
      " 30  delta_price_lag                       float16\n",
      " 31  delta_revenue_lag_1                   float16\n",
      " 32  month                                 int8   \n",
      " 33  day_cnt                               int8   \n",
      " 34  item_first_sale                       float64\n",
      " 35  item_last_sale                        float64\n",
      " 36  item_shop_first_sale                  float64\n",
      " 37  item_shop_last_sale                   float64\n",
      "dtypes: float16(25), float64(4), int16(1), int8(8)\n",
      "memory usage: 543.1 MB\n"
     ]
    }
   ],
   "source": [
    "matrix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.to_pickle('data.pkl')\n",
    "del matrix\n",
    "#del cache\n",
    "del group\n",
    "del items\n",
    "del shops\n",
    "del cats\n",
    "del train\n",
    "# leave test for submission\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
